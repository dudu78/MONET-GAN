{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport tensorflow as tf\n\n\n\nfrom kaggle_datasets import KaggleDatasets\n\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom IPython import display\nfrom PIL import Image\nimport numpy as np\n\nfrom tensorflow.keras.layers import Input, Reshape, Dropout, Dense \nfrom tensorflow.keras.layers import Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Activation, ZeroPadding2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport os \nimport time\nimport matplotlib.pyplot as plt\n\n#'kaggle datasets download -d spandan2/cats-faces-64x64-for-generative-models'\nBUFFER_SIZE = 1193\nBATCH_SIZE = 64\n\n","metadata":{"id":"PcUy0dLbCtvw","execution":{"iopub.status.busy":"2022-01-05T13:14:10.910686Z","iopub.execute_input":"2022-01-05T13:14:10.911533Z","iopub.status.idle":"2022-01-05T13:14:10.923105Z","shell.execute_reply.started":"2022-01-05T13:14:10.911496Z","shell.execute_reply":"2022-01-05T13:14:10.922333Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"J0pB8qIOHrp3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ngd0OUZyCtv8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"LMrQiLIboby2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.load('../input/monet-to-numpy/monet.npy')","metadata":{"id":"ByUIl-zho-Pw","execution":{"iopub.status.busy":"2022-01-05T13:14:10.925661Z","iopub.execute_input":"2022-01-05T13:14:10.926252Z","iopub.status.idle":"2022-01-05T13:14:11.084433Z","shell.execute_reply.started":"2022-01-05T13:14:10.926175Z","shell.execute_reply":"2022-01-05T13:14:11.083692Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"\nprint(x_train.shape)\ntrain_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ntest = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(1)","metadata":{"id":"Aos6mSaECtwO","execution":{"iopub.status.busy":"2022-01-05T13:14:11.085998Z","iopub.execute_input":"2022-01-05T13:14:11.086266Z","iopub.status.idle":"2022-01-05T13:14:11.795226Z","shell.execute_reply.started":"2022-01-05T13:14:11.086232Z","shell.execute_reply":"2022-01-05T13:14:11.794511Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"plt.imshow(x_train[0]*0.5 +0.5)","metadata":{"id":"JmZlIwOqCtwY","execution":{"iopub.status.busy":"2022-01-05T13:14:11.796315Z","iopub.execute_input":"2022-01-05T13:14:11.796552Z","iopub.status.idle":"2022-01-05T13:14:12.038135Z","shell.execute_reply.started":"2022-01-05T13:14:11.796517Z","shell.execute_reply":"2022-01-05T13:14:12.037497Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"def build_generator3(channels = 3):\n    GENERATE_RES = 3\n    model = Sequential()\n    N = 512\n    N_DIM = 8\n    model.add(Dense(N_DIM*N_DIM*N,activation=\"relu\",input_shape=(100,)))\n    model.add(Reshape((N_DIM,N_DIM,N)))\n\n    model.add(UpSampling2D())\n    model.add(Conv2D(N,kernel_size=3,padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n\n    model.add(UpSampling2D())\n    model.add(Conv2D(N/2,kernel_size=3,padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n   \n    # Output resolution, additional upsampling\n    model.add(UpSampling2D())\n    model.add(Conv2D(N/4,kernel_size=3,padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n\n    model.add(UpSampling2D())\n    model.add(Conv2D(N/8,kernel_size=3,padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n\n\n\n    # Final CNN layer\n    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n    model.add(Activation(\"tanh\"))\n\n    return model\ngenerator =build_generator3()\ngenerator.summary()\n\n","metadata":{"id":"fRzD4yxcKrNk","execution":{"iopub.status.busy":"2022-01-05T13:14:12.040507Z","iopub.execute_input":"2022-01-05T13:14:12.041003Z","iopub.status.idle":"2022-01-05T13:14:12.176843Z","shell.execute_reply.started":"2022-01-05T13:14:12.040968Z","shell.execute_reply":"2022-01-05T13:14:12.176171Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"\ndef build_discriminator3( image_shape = [128, 128, 3]):\n    model = Sequential()\n    N = 512\n    model.add(Conv2D(N/16, kernel_size=3, strides=2, input_shape=image_shape, \n                     padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(N/8, kernel_size=3, strides=2, padding=\"same\"))\n    \n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(N/4, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(N/2, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n  \n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(N, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n\n    return model\ndiscriminator =build_discriminator3()\ndiscriminator.summary()\n\n\n","metadata":{"id":"90EAiJk9O0--","execution":{"iopub.status.busy":"2022-01-05T13:14:12.178019Z","iopub.execute_input":"2022-01-05T13:14:12.178256Z","iopub.status.idle":"2022-01-05T13:14:12.304420Z","shell.execute_reply.started":"2022-01-05T13:14:12.178225Z","shell.execute_reply":"2022-01-05T13:14:12.303720Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"4*524288","metadata":{"id":"_b4CGrEKjyIi","execution":{"iopub.status.busy":"2022-01-05T13:14:12.307061Z","iopub.execute_input":"2022-01-05T13:14:12.307247Z","iopub.status.idle":"2022-01-05T13:14:12.315679Z","shell.execute_reply.started":"2022-01-05T13:14:12.307226Z","shell.execute_reply":"2022-01-05T13:14:12.314725Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"#generator = build_generator2()\n\n#generator, layers_gen = auto_build_generator(128)\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training = False)\n\n\nplt.imshow(generated_image[0]*0.5 +0.5)","metadata":{"id":"xdlEKyMYCtwh","execution":{"iopub.status.busy":"2022-01-05T13:14:12.316912Z","iopub.execute_input":"2022-01-05T13:14:12.317530Z","iopub.status.idle":"2022-01-05T13:14:12.553053Z","shell.execute_reply.started":"2022-01-05T13:14:12.317497Z","shell.execute_reply":"2022-01-05T13:14:12.552416Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"\n\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","metadata":{"id":"ygUZBFvjCtwp","execution":{"iopub.status.busy":"2022-01-05T13:14:12.554239Z","iopub.execute_input":"2022-01-05T13:14:12.554547Z","iopub.status.idle":"2022-01-05T13:14:12.559210Z","shell.execute_reply.started":"2022-01-05T13:14:12.554512Z","shell.execute_reply":"2022-01-05T13:14:12.558326Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    coeff = 1\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss*coeff","metadata":{"id":"0nvKZozYCtww","execution":{"iopub.status.busy":"2022-01-05T13:14:12.560867Z","iopub.execute_input":"2022-01-05T13:14:12.561141Z","iopub.status.idle":"2022-01-05T13:14:12.568286Z","shell.execute_reply.started":"2022-01-05T13:14:12.561098Z","shell.execute_reply":"2022-01-05T13:14:12.567730Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"def generator_loss(fake_output):\n    coeff = 1\n    return cross_entropy(tf.ones_like(fake_output)*coeff, fake_output*coeff)\n\n\ngenerator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)","metadata":{"id":"EW8CTytMCtw3","execution":{"iopub.status.busy":"2022-01-05T13:14:12.569750Z","iopub.execute_input":"2022-01-05T13:14:12.570079Z","iopub.status.idle":"2022-01-05T13:14:12.577263Z","shell.execute_reply.started":"2022-01-05T13:14:12.570044Z","shell.execute_reply":"2022-01-05T13:14:12.576590Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)\n\nEPOCHS = 500\nnoise_dim = 100\nnum_examples_to_generate = 16\nnum_trie = 1\n# We will reuse this seed overtime (so it's easier)\n# to visualize progress in the animated GIF)\nseed = tf.random.normal([num_examples_to_generate*num_trie, noise_dim])","metadata":{"id":"GyiI_oGHCtw9","execution":{"iopub.status.busy":"2022-01-05T13:14:12.579916Z","iopub.execute_input":"2022-01-05T13:14:12.580145Z","iopub.status.idle":"2022-01-05T13:14:12.592859Z","shell.execute_reply.started":"2022-01-05T13:14:12.580115Z","shell.execute_reply":"2022-01-05T13:14:12.592157Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# Notice the use of `tf.function`\n# This annotation causes the function to be \"compiled\".\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        \n        generated_images = generator(noise, training=True)\n\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\n    return gen_loss, disc_loss\n    ","metadata":{"id":"gd9L7g9UCtxB","execution":{"iopub.status.busy":"2022-01-05T13:14:12.594140Z","iopub.execute_input":"2022-01-05T13:14:12.594518Z","iopub.status.idle":"2022-01-05T13:14:12.602469Z","shell.execute_reply.started":"2022-01-05T13:14:12.594480Z","shell.execute_reply":"2022-01-05T13:14:12.601724Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"\n\n    ","metadata":{"id":"8JxZHgLlKtof"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_best_pred(gen, disc, seeds, num):\n    \n    num_iter = num\n    best_pred = []\n    for i in range(16):\n        ite = i*num_iter\n        s = seeds[ite:ite+num_iter]\n        \n        preds = gen(s, training=False)\n        \n        preds_disc = disc(preds)\n        best = np.argmax(preds_disc)\n        best_pred.append(preds[best])\n    return np.array(best_pred)\n\n\ndef show_best(gen, disc):\n    samples = 16\n    among = 2\n    test_input = tf.random.normal([samples*among, noise_dim])\n    predictions = get_best_pred(gen, disc, test_input, among)\n    pred_disc = disc(predictions, training=False)\n    fig = plt.figure(figsize=(32,32))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(predictions[i]*0.5 +0.4 )\n        plt.axis('off')\n        \n    plt.show()\n    print(np.array(pred_disc).reshape(4,4))\n    print(predictions.shape[0])\n    print(np.min(predictions[i]))","metadata":{"id":"GM6pcOKwCtxF","execution":{"iopub.status.busy":"2022-01-05T13:14:12.605742Z","iopub.execute_input":"2022-01-05T13:14:12.605939Z","iopub.status.idle":"2022-01-05T13:14:12.615194Z","shell.execute_reply.started":"2022-01-05T13:14:12.605918Z","shell.execute_reply":"2022-01-05T13:14:12.614463Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"def train(dataset, epochs):\n    for epoch in range(epochs):\n        start = time.time()\n        \n        G_loss = []\n        D_loss = []\n        for i,image_batch in enumerate(dataset):\n            #print('iteration : ', i)\n            g_loss, d_loss = train_step(image_batch)\n            G_loss.append(g_loss)\n            D_loss.append(d_loss)\n        \n        G_loss = np.mean(G_loss)\n        D_loss = np.mean(D_loss)\n        \n        # Produce images for the GIF as we go\n        display.clear_output(wait=True)\n        generate_and_save_images(generator, discriminator,epoch + 1,seed)\n                                 \n                                 \n                                 \n    \n        # Save the model every 15 epochs\n        #checkpoint.save(file_prefix = checkpoint_prefix)\n\n        print ('Time for epoch {} is {} sec... G_loss = {} , D_loss = {}'.format(epoch + 1, time.time()-start, G_loss, D_loss))\n\n      # Generate after the final epoch\n    #display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                            discriminator,\n                            epochs,\n                            seed)","metadata":{"id":"K-ZSwBZwCtxM","execution":{"iopub.status.busy":"2022-01-05T13:14:12.616563Z","iopub.execute_input":"2022-01-05T13:14:12.616882Z","iopub.status.idle":"2022-01-05T13:14:12.626997Z","shell.execute_reply.started":"2022-01-05T13:14:12.616848Z","shell.execute_reply":"2022-01-05T13:14:12.626228Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_images(model, disc, epoch, test_input):\n    # Notice `training` is set to False.\n    # This is so all layers run in inference mode (batchnorm).\n    \n    predictions = model(test_input, training=False)\n    pred_disc = disc(predictions)\n    \n    #predictions = get_best_pred(model, disc, test_input)\n    #pred_disc = disc(predictions)\n    \n    fig = plt.figure(figsize=(8,8))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(predictions[i]*0.5 +0.5)\n        plt.axis('off')\n\n    #plt.savefig('out/image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()\n    #print(pred_disc)\n    print(np.array(pred_disc).reshape(4,4))\n    ","metadata":{"id":"W3AkYUXpCtxQ","execution":{"iopub.status.busy":"2022-01-05T13:14:12.628328Z","iopub.execute_input":"2022-01-05T13:14:12.628610Z","iopub.status.idle":"2022-01-05T13:14:12.637806Z","shell.execute_reply.started":"2022-01-05T13:14:12.628574Z","shell.execute_reply":"2022-01-05T13:14:12.637185Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"iZVQ4TDytwgo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"essaie = '2'\n#generator.load_weights('../input/monetgan/generatorMONET1.h5')\n#discriminator.load_weights('../input/monetgan/discriminatorMONET1.h5')","metadata":{"id":"LLt5RPQPu7WK","execution":{"iopub.status.busy":"2022-01-05T13:14:12.639237Z","iopub.execute_input":"2022-01-05T13:14:12.639492Z","iopub.status.idle":"2022-01-05T13:14:12.645972Z","shell.execute_reply.started":"2022-01-05T13:14:12.639461Z","shell.execute_reply":"2022-01-05T13:14:12.645294Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"\nessaie = '2'\n\n\nfor i in range(10):\n  print('epoch i = ', i*10)\n  show_best(generator, discriminator)\n  train(train_dataset, 10)\n  print('epoch i = ', i)\n\n  generator.save_weights('generatorMONET1.h5')\n  discriminator.save_weights('discriminatorMONET1.h5')","metadata":{"id":"DUHeFWMwCtxa","execution":{"iopub.status.busy":"2022-01-05T14:04:33.244291Z","iopub.execute_input":"2022-01-05T14:04:33.244554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.save_weights('/content/drive/My Drive/GAN_MONET/generatorMONET'+ str(essaie) +'.h5')\ndiscriminator.save_weights('/content/drive/My Drive/GAN_MONET/discriminatorMONET'+ str(essaie) +'.h5')","metadata":{"id":"ZspN_OJ-M-tL","execution":{"iopub.status.busy":"2022-01-05T14:04:09.563776Z","iopub.status.idle":"2022-01-05T14:04:09.564601Z","shell.execute_reply.started":"2022-01-05T14:04:09.564362Z","shell.execute_reply":"2022-01-05T14:04:09.564385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  generator.save_weights('generatorMONET1.h5')\n  discriminator.save_weights('discriminatorMONET1.h5')","metadata":{"id":"T6RJbImkfXzp","execution":{"iopub.status.busy":"2022-01-05T14:04:09.565614Z","iopub.status.idle":"2022-01-05T14:04:09.566375Z","shell.execute_reply.started":"2022-01-05T14:04:09.566156Z","shell.execute_reply":"2022-01-05T14:04:09.566177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nois = tf.random.normal([1, noise_dim])\nimag = generator(nois, training=False)\n\nout = discriminator(imag, training = False)\nprint(out)\nit = iter(test)\nfloat(discriminator_loss(next(it), out))","metadata":{"id":"QO80zvonx2t9","execution":{"iopub.status.busy":"2022-01-05T14:04:09.567434Z","iopub.status.idle":"2022-01-05T14:04:09.567979Z","shell.execute_reply.started":"2022-01-05T14:04:09.567752Z","shell.execute_reply":"2022-01-05T14:04:09.567778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"gb3D0qEFwW9Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Jjals5NECtxn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"TmWCe9ShCtxv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"SuEgc_3TCtxz"},"execution_count":null,"outputs":[]}]}